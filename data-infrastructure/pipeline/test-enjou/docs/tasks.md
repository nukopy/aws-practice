# タスク

## やること概観

- ひとまずの TODO
  - DynamoDB 更新 -> Lambda 発火 -> Firehose -> S3
  - CloudWatch Logs の検証
    - サブスクリプションフィルタの登録・動作確認
      - Lambda 関数の作成に伴って作られるロググループを用いると print デバッグできて楽
  - Avro in S3 の検証
    - S3 に保存したときに Avro 変換をできるか
  - TODO の分解（タスクの分解）

- 最終目標
  - DynamoDB 更新 -> Firehose -> JSON のまま S3 -> S3 の保存をトリガーに Avro 変換を走らせる
  - CloudWatch Logs 更新 -> Firehose -> JSON のまま S3 -> S3 の保存をトリガーに Avro 変換を走らせる
    - Firehose で Lambda を発火してメタデータとかのフィルタリングを行う

## TODO の分解

- [x] DynamoDB 作り直す
- [x] 一旦 DynamoDB から新しく作り直す？
  - 既存のものは残しておく
- [x] CloudWatch Logs の検証
  - [x] ストリームの作成
  - [x] ロググループの作成
  - [x] サブスクリプションフィルタの作成

## 次回：2020/11/11 以降

次回申し送り

- **ロググループじゃなくて，ログストリーム単位で Firehose の"レコード" が出力されるのが罠**

- [x] CloudWatch Logs --(サブスクリプションフィルタ)--> Firehose -> S3（4.5 h）
  - [x] ログのメタデータの除去（2.5 h） **2020/11/06 DONE**
    - [x] doc 読み：Amazon Kinesis Data Firehose におけるデータ変換（30 m）
    - [x] Firehose 内で "Transformation with AWS Lambda" を読んでメタデータを除去し，タイムスタンプとログ出力という純粋なログのみを S3 に吐けるようにする（2 h）
      - **ロググループじゃなくて，ログストリーム単位で Firehose の"レコード" が出力されるのが罠**
        - つまり，ログ 1 行ごとには吐き出されない
      - JSON line というのがログ出力の主流になってる
      - JSON になってるログのみを返すようにフィルターする（Lambda 自身の出力は省きたい）
      - JSON の改行忘れずに
        - Python オブジェクトでなく，改行付き文字列を S3 に吐く
  - [x] S3 にファイルをアップロードしたのをトリガーに Lambda を発火し avro へ変換（3 h）
    - [x] S3 にファイルアップロードしたのをトリガーに Lambda を発火させる
    - [x] Lambda でファイル操作を行う 1: ファイル名をログへ出力
    - [x] Lambda でファイル操作を行う 2: ファイル名をログへ出力し，avro 形式へ変換したものを S3 に保存

## 2020/11/11 20:00 ~

- [ ] ここまでの流れを全て SAM（CloudFormation）でデプロイできるようにする
  - [ ] SAM のキャッチアップ
    - [ ] そもそも CloudFormation，SAM が何なのかを知る
    - [ ] まずは Lambda の一番単純なやつからデプロイ．
      - IAM のロールとかポリシー周りでハマりそう
      - ちょっとずつデプロイする範囲を広げていく．いきなりでかくデプロイしない．

---

闇雲にやるとあっという間に時間がなくなるから，．
ただし，ドキュメントをちゃんと読むことを大前提にする．
Qiita とかはあくまでも雰囲気を掴むくらいにとどめる．

## 柳さんへの質問

- AWS のリソースの命名方法
  - どういう決まりを作ると良いか
